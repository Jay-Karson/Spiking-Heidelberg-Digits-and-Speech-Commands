{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "47d5313e-c29d-4581-a9c7-a45122337069",
      "metadata": {
        "id": "47d5313e-c29d-4581-a9c7-a45122337069"
      },
      "source": [
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"300\">](https://github.com/jeshraghian/snntorch/)\n",
        "\n",
        "# Training SNNs to do something\n",
        "### Tutorial written by Dr. Jill Biden\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/quickstart.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/jeshraghian/snntorch/) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/jeshraghian/snntorch/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oll2NNFeG1NG",
      "metadata": {
        "id": "oll2NNFeG1NG"
      },
      "source": [
        "For a comprehensive overview on how SNNs work, and what is going on under the hood, [then you might be interested in the snnTorch tutorial series available here.](https://snntorch.readthedocs.io/en/latest/tutorials/index.html)\n",
        "The snnTorch tutorial series is based on the following paper. If you find these resources or code useful in your work, please consider citing the following source:\n",
        "\n",
        "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". Proceedings of the IEEE, 111(9) September 2023.](https://ieeexplore.ieee.org/abstract/document/10242251) </cite>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hDnIEHOKB8LD",
      "metadata": {
        "id": "hDnIEHOKB8LD"
      },
      "outputs": [],
      "source": [
        "!pip install snntorch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WL487gZW1Agy",
      "metadata": {
        "id": "WL487gZW1Agy"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn\n",
        "import snntorch as snn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EYf13Gtx1OCj",
      "metadata": {
        "id": "EYf13Gtx1OCj"
      },
      "source": [
        "## 1. The MNIST Dataset\n",
        "### 1.1 Dataloading\n",
        "Define variables for dataloading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eo4T5MC21hgD",
      "metadata": {
        "id": "eo4T5MC21hgD"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "data_path='/tmp/data/mnist'\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "myFKqNx11qYS",
      "metadata": {
        "id": "myFKqNx11qYS"
      },
      "source": [
        "Load dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3GdglZjK04cb",
      "metadata": {
        "id": "3GdglZjK04cb"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 A description of the data\n",
        "Describe what your data is. MNIST is a dataset of 60,000 images in the training set and 10,000 images in the test set of grayscale handwritten numerical digits. The goal is to classify the digit written in each image between 0-9.\n",
        "\n",
        "You can further clarify what your data is by querying the size of one sample of data and describing what each dimension refers to.\n",
        "* The spatial dimensions of MNIST are $28\\times 28$\n",
        "* The image is grayscale so the channel size is $1$\n",
        "* There are no time-varying components, so there is no sequence length\n",
        "\n",
        "Additionally, provide visualizations of your data as either an image, video, audio, or several frames, or whatever plot that makes the most sense for your data."
      ],
      "metadata": {
        "id": "cGmB_RhWIklU"
      },
      "id": "cGmB_RhWIklU"
    },
    {
      "cell_type": "code",
      "source": [
        "for data, label in iter(train_loader):\n",
        "  print(data.size())\n",
        "  break"
      ],
      "metadata": {
        "id": "Rreb9xV6ISEr"
      },
      "id": "Rreb9xV6ISEr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternatively:\n",
        "For those of you doing ECE 293 projects that are focused on new concepts, such as STDP, or quantized SNNs, delta RNNs, etc., then please give a basic background of the theory using basic and well-defined math, code-blocks, and figures to explain the concept clearly."
      ],
      "metadata": {
        "id": "WheI_GNHK58S"
      },
      "id": "WheI_GNHK58S"
    },
    {
      "cell_type": "markdown",
      "id": "BtJBOtez11wy",
      "metadata": {
        "id": "BtJBOtez11wy"
      },
      "source": [
        "## 2. Define Network with snnTorch\n",
        "We will use a network with one hidden layer of architecture size $784-300-10$. Convolutions may give better results but we'll use fully-connected layers for the sake of speed/simplicity, and because MNIST is a simple enough task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JM2thnrc10rD",
      "metadata": {
        "id": "JM2thnrc10rD"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_inputs = 784 # number of inputs\n",
        "        num_hidden = 300 # number of hidden neurons\n",
        "        num_outputs = 10 # number of classes (i.e., output neurons)\n",
        "\n",
        "        beta1 = 0.9 # global decay rate for all leaky neurons in layer 1\n",
        "        beta2 = torch.rand((num_outputs), dtype = torch.float) # independent decay rate for each leaky neuron in layer 2: [0, 1)\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta1) # not a learnable decay rate\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Leaky(beta=beta2, learn_beta=True) # learnable decay rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
        "        mem2 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
        "        spk2_rec = [] # record output spikes\n",
        "        mem2_rec = [] # record output hidden states\n",
        "\n",
        "        for step in range(num_steps): # loop over time\n",
        "            cur1 = self.fc1(x.flatten(1))\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2) # record spikes\n",
        "            mem2_rec.append(mem2) # record membrane\n",
        "\n",
        "        return torch.stack(spk2_rec), torch.stack(mem2_rec)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "net = Net().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sIrJnBoz490c",
      "metadata": {
        "id": "sIrJnBoz490c"
      },
      "source": [
        "## 3. Define the Forward Pass\n",
        "Now define the forward pass over multiple time steps of simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hWa8f_We4-8z",
      "metadata": {
        "id": "hWa8f_We4-8z"
      },
      "outputs": [],
      "source": [
        "from snntorch import utils\n",
        "\n",
        "def forward_pass(net, data, num_steps):\n",
        "  spk_rec = [] # record spikes over time\n",
        "\n",
        "  for step in range(num_steps): # loop over time\n",
        "      spk_out, mem_out = net(data) # one time step of the forward-pass\n",
        "      spk_rec.append(spk_out) # record spikes\n",
        "\n",
        "  return torch.stack(spk_rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9nGhh2_25NU8",
      "metadata": {
        "id": "9nGhh2_25NU8"
      },
      "source": [
        "Define the optimizer and loss function. Here, we use the MSE Count Loss, which counts up the total number of output spikes at the end of the simulation run. The correct class has a target firing rate of 80% of all time steps, and incorrect classes are set to 20%."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48_7sIT86iUJ",
      "metadata": {
        "id": "48_7sIT86iUJ"
      },
      "source": [
        "## 4. Training Loop\n",
        "\n",
        "Now for the training loop. The predicted class will be set to the neuron with the highest firing rate, i.e., a rate-coded output. We will just measure accuracy on the training set. This training loop follows the same syntax as with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kGZf7Hr55psl",
      "metadata": {
        "id": "kGZf7Hr55psl"
      },
      "outputs": [],
      "source": [
        "import snntorch.functional as SF\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
        "\n",
        "num_epochs = 1 # run for 1 epoch - each data sample is seen only once\n",
        "num_steps = 25  # run for 25 time steps\n",
        "\n",
        "loss_hist = [] # record loss over iterations\n",
        "acc_hist = [] # record accuracy over iterations\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        net.train()\n",
        "        spk_rec, _ = net(data) # forward-pass\n",
        "        loss_val = loss_fn(spk_rec, targets) # loss calculation\n",
        "        optimizer.zero_grad() # null gradients\n",
        "        loss_val.backward() # calculate gradients\n",
        "        optimizer.step() # update weights\n",
        "        loss_hist.append(loss_val.item()) # store loss\n",
        "\n",
        "        # print every 25 iterations\n",
        "        if i % 25 == 0:\n",
        "          net.eval()\n",
        "          print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
        "\n",
        "          # check accuracy on a single batch\n",
        "          acc = SF.accuracy_rate(spk_rec, targets)\n",
        "          acc_hist.append(acc)\n",
        "          print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
        "\n",
        "        # uncomment for faster termination\n",
        "        # if i == 150:\n",
        "        #     break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It would help to include a figure of your training loss curve, too."
      ],
      "metadata": {
        "id": "yAWxZl1VKWS0"
      },
      "id": "yAWxZl1VKWS0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Metrics\n",
        "### 5.1 Accuracy Metrics\n"
      ],
      "metadata": {
        "id": "Epm1K7u8KLQW"
      },
      "id": "Epm1K7u8KLQW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CXCggOzk2vYF",
      "metadata": {
        "id": "CXCggOzk2vYF"
      },
      "outputs": [],
      "source": [
        "# function to measure accuracy on full test set\n",
        "def test_accuracy(data_loader, net, num_steps):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    net.eval()\n",
        "\n",
        "    data_loader = iter(data_loader)\n",
        "    for data, targets in data_loader:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      spk_rec, _ = net(data)\n",
        "\n",
        "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
        "      total += spk_rec.size(1)\n",
        "\n",
        "  return acc/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ias_TerdCMoG",
      "metadata": {
        "id": "ias_TerdCMoG"
      },
      "outputs": [],
      "source": [
        "print(f\"Test set accuracy: {test_accuracy(test_loader, net, num_steps)*100:.3f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Any other metrics that might be relevant, e.g., spike-rate?"
      ],
      "metadata": {
        "id": "fSswVeaZKTGK"
      },
      "id": "fSswVeaZKTGK"
    },
    {
      "cell_type": "markdown",
      "id": "-iSGTq0Q3Lcm",
      "metadata": {
        "id": "-iSGTq0Q3Lcm"
      },
      "source": [
        "# Conclusion\n",
        "That's it for the quick intro to training MNIST with snnTorch!\n",
        "\n",
        "Provide a formal reference to your dataset or your task.\n",
        "\n",
        "Feel free to ping me (Jason) throughout the quarter with your tutorial as I'd be happy to give regular feedback. Ideally, it'd be in a state where we can upload it to the snnTorch documentation so that everyone else can benefit from it."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c8b87b4648a8d1ba1118329c37c7c28a2ff48490805f0e62ea19d4b1b49e5656"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}